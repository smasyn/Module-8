<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Practical Machine Learning: Predicting Weightlifting Performance&#39;</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>





<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h1>Practical Machine Learning: Predicting Weightlifting Performance&#39;</h1>

<p>Paper submitted by S. Masyn, <a href="mailto:smasyn@yahoo.com">smasyn@yahoo.com</a>, as project work of the Practical Machine Learning Course.</p>

<p>May,24, 2015</p>

<h1>Introduction</h1>

<p>Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.</p>

<p>More information is available from the website here: <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a> (see the section on the Weight Lifting Exercise Dataset). </p>

<h1>Synopsis</h1>

<p>In this exercise we explore the data set from Weight Lifting Exercise Dataset, clean and tidy up the tidy and assess some models predictin weightlifting performance</p>

<h1>Summary</h1>

<h2>Required Libraries</h2>

<p>caret,ggplot2, randomForest, e1071 and knitr are required libraries</p>

<h1>Data Handling</h1>

<p>The data was extracted from the Weight Lifting Exercise Dataset. Several parameters contain NA values; after looking at the data structure the following could be determined: gyros,accel, total_accel, magnet, roll, pitch and yaw features  have non-missing values. these are retained from the data set.</p>

<pre><code>## [1] 1287472
</code></pre>

<pre><code>## [1] 2000
</code></pre>

<p>After subsetting, 52 parameters contribute to the data, none of these parameters have NA values</p>

<pre><code>## [1] 0
</code></pre>

<pre><code>## [1] 0
</code></pre>

<p>A potential further reduction of the contributing features is explored by applying a Principal Component Analysis</p>

<h1>Principal Component Analysis</h1>

<p>12 parameters contribute to 80% of the variance; Later, the model using the Principal Components is explored</p>

<h1>Cross Validation</h1>

<p>To validate the model a cross validation data set is constructed. 80% data used as actual training set, 20% as test set. Centering and Scaling is used, not using it did not show any better or worse results </p>

<p>Finally, several models are being fitted</p>

<p>After more than 1 hour of processing the random Forest model got abandoned (method=&ldquo;rf&rdquo;)
The glm model raises accuracy warnings, for which I was unbale to find a solution
The QDA showed best accuracy: QDA (89%) LDA(70%) PCA(56%)</p>

<pre><code>## Quadratic Discriminant Analysis 
## 
## 15699 samples
##    52 predictor
##     5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; 
## 
## Pre-processing: centered, scaled 
## Resampling: Cross-Validated (10 fold, repeated 10 times) 
## 
## Summary of sample sizes: 14129, 14131, 14130, 14129, 14128, 14129, ... 
## 
## Resampling results
## 
##   Accuracy   Kappa      Accuracy SD  Kappa SD   
##   0.8936371  0.8657083  0.007409249  0.009311722
## 
## 
</code></pre>

<h1>Expected Out-of-Sample Error</h1>

<p>We would expect that the out-of-sample error is less on non-training data
Using the cross validation test set the out-of-sample-error of the prediction model can be estimated</p>

<pre><code>## [1] 0.9006943
</code></pre>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 4137  134    0    4    1
##          B  161 2592  120   10   77
##          C   94  284 2598  342  118
##          D   62    8   12 2192   69
##          E   10   20    8   25 2621
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9007          
##                  95% CI : (0.8959, 0.9053)
##     No Information Rate : 0.2843          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.8746          
##  Mcnemar&#39;s Test P-Value : &lt; 2.2e-16       
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9267   0.8532   0.9489   0.8519   0.9082
## Specificity            0.9876   0.9709   0.9353   0.9885   0.9951
## Pos Pred Value         0.9675   0.8757   0.7561   0.9356   0.9765
## Neg Pred Value         0.9714   0.9650   0.9886   0.9715   0.9796
## Prevalence             0.2843   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2635   0.1651   0.1655   0.1396   0.1670
## Detection Prevalence   0.2724   0.1885   0.2189   0.1492   0.1710
## Balanced Accuracy      0.9572   0.9121   0.9421   0.9202   0.9516
</code></pre>

<pre><code>## [1] 0.89039
</code></pre>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1034   43    2    1    0
##          B   46  623   41    4   28
##          C   19   80  636   87   21
##          D   15    5    3  544   16
##          E    2    8    2    7  656
## 
## Overall Statistics
##                                        
##                Accuracy : 0.8904       
##                  95% CI : (0.8802, 0.9)
##     No Information Rate : 0.2845       
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16    
##                                        
##                   Kappa : 0.8615       
##  Mcnemar&#39;s Test P-Value : &lt; 2.2e-16    
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9265   0.8208   0.9298   0.8460   0.9098
## Specificity            0.9836   0.9624   0.9361   0.9881   0.9941
## Pos Pred Value         0.9574   0.8396   0.7544   0.9331   0.9719
## Neg Pred Value         0.9712   0.9572   0.9844   0.9704   0.9800
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2636   0.1588   0.1621   0.1387   0.1672
## Detection Prevalence   0.2753   0.1891   0.2149   0.1486   0.1721
## Balanced Accuracy      0.9551   0.8916   0.9330   0.9171   0.9520
</code></pre>

<h1>Results on the Submission</h1>

<pre><code>##  [1] A A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E
</code></pre>

<p>Finally the results were submitted to the Coursera Website, only 7/20 were correct, which is a disappointing result
Would love to see the correct approach</p>

</body>

</html>
